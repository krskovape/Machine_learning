{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KUCHAŘKA na druhej testík ML\n",
    "nemáte zač"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLu, dělám ReLu\n",
    "jsem tý neuronce nejspíš k smíchu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTY\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42) # případně změnit seed\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "\n",
    "# PyTorch imports \n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA - simulace\n",
    "pokud nám nedá data, tak je simulujeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate_images import generate_image_shapes\n",
    "\n",
    "# testuju, jaký data dostanu a pak na ně aplikuju class SimDataset\n",
    "height, width, count = 28, 28, 9\n",
    "noise = 0.2\n",
    "X, Y, y_label = generate_image_shapes(height, width, count, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (9, 1, 28, 28)\n",
      "[0 1 2]\n",
      "label 2 = circle\n",
      "label 0 = square\n",
      "label 2 = circle\n",
      "label 2 = circle\n",
      "label 0 = square\n",
      "label 0 = square\n",
      "label 2 = circle\n",
      "label 1 = triangle\n",
      "label 2 = circle\n"
     ]
    }
   ],
   "source": [
    "# data exploration\n",
    "print(f\"X shape: {X.shape}\")\n",
    "\n",
    "print(np.unique(y_label))   # kolik máme klasifikačních tříd\n",
    "\n",
    "object_shapes = ['square', 'triangle', 'circle']  \n",
    "for label in y_label: \n",
    "    print(f'label {label} = {object_shapes[label]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# KOUKÁME NA DATA\n",
    "# printneme si třetí obrázek\n",
    "image_no=3\n",
    "print(f'Label: {y_label[image_no]}')\n",
    "plt.imshow(X[image_no][0,:,:])\n",
    "\n",
    "# a tady mrkneme na všechny\n",
    "plt.figure(figsize=(10,10)) \n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X[i][0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**class SimDataset** \n",
    "- znovu vytváří data pomocí `generate_image_shapes` a dědí z `Dataset`, takže už má parametry toho\n",
    "- volám ji pak v `get_data_loaders` a pomocí toho vytvořím testovací a trénovací data\n",
    "- musím to udělat? protože chci dělat deep learning, takže na data musím aplikovat `DataLoader` (je to class z torch knihovny) <-- prostě musím a basta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class to generate simulated images, masks and labels and getting an image when called  \n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, height, width, count, noise):\n",
    "        self.input_images, self.target_masks, self.target_labels = generate_image_shapes(height, width, count, noise)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    # indexing operation on objects; enable instances of the class \n",
    "    # to use the indexing syntax to retrieve elements\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        label= self.target_labels[idx] \n",
    "\n",
    "        return [image, mask, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINUJEME ROZDĚLENÍ DAT NA TRÉNOVACÍ A TESTOVACÍ \n",
    "def get_data_loaders(height, width, noise, train_size, test_size, batch_size=5):\n",
    "\n",
    "    # simulated based on given parameters\n",
    "    train_set = SimDataset(height, width, train_size, noise) \n",
    "    test_set = SimDataset(height, width, test_size, noise) \n",
    "\n",
    "    # z jednotlivých obrázků DataLoader udělá jakoby balíček\n",
    "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DĚLÍME DATA NA TRÉNOVACÍ A TESTOVACÍ\n",
    "batch_size = 20\n",
    "height, width = 28, 28  # image size - ovlivňuje sekvenci konvoluce\n",
    "noise = 0.5 \n",
    "\n",
    "# 500 - ale může být cokoliv jiného, Brodský prý preferuje 50 a 50\n",
    "train_dataloader, test_dataloader = get_data_loaders(height, width, noise, train_size = 500, test_size = 500, \n",
    "                                                     batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trochu data exploration; X.shape je torch.Size([20, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# nakonec uložíme data z train_dataloader do proměnných, aby to neuronka schroupala\n",
    "X, Y, y_label = next(iter(train_dataloader))\n",
    "print(f\"Trochu data exploration; X.shape je {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL - definování\n",
    "budeme dělat:\n",
    "- convoluci, pak ReLu a MaxPooling\n",
    "- potom uděláme flatten\n",
    "- a nakonec spojíme\n",
    "a to je děti jeden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape outputu 1: torch.Size([20, 9, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2b0917addd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# KONVOLUCE = definuju parametry pro moji konvoluci\n",
    "\n",
    "# stride = krok posunu okna o daný počet pixelů (jakoby kolik přeskočím) v obou směrech\n",
    "# padding = pro zachování původního rozměru inputu; když padding = 0, tak tam NENÍ!!!\n",
    "conv = nn.Conv2d(in_channels = 1, out_channels = 9, kernel_size = 3, stride = 1, padding = 1) \n",
    "\n",
    "# zkoušíme to použít, jestli to funguje (optional)\n",
    "output1 = conv(X)\n",
    "print(f\"Shape outputu 1: {output1.shape}\") \n",
    "\n",
    "# LET'S PLOT IT\n",
    "# první číslo = počet obrázků v datasetu\n",
    "# druhý číslo = počet bandů jednoho obrázku\n",
    "# ty dvě další je počet pixelů\n",
    "plt.imshow(output1[19, 8, :, :].detach())    # u čísel nemůžu jít výš než na n-1 oproti mého počtu obrázků/bands\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape outputu po ReLu: torch.Size([20, 9, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b0917dfed0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RELU (activation layer aktivuje části, které si myslí, že jsou important) \n",
    "relu = nn.ReLU()    # definice\n",
    "\n",
    "# zkoušíme to tady udělat, jestli funguje, ale je to optional\n",
    "output2 = relu(output1)\n",
    "print(f\"Shape outputu po ReLu: {output2.shape}\")    # neměl by se shape změnit oproti conv\n",
    "\n",
    "# koukáme, co nám ReLu rozsvítila\n",
    "plt.imshow(output2[0, 2, :, :].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape po max pooling: torch.Size([20, 9, 14, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b08e95f790>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAX POOLING\n",
    "pool = nn.MaxPool2d(kernel_size=2)  # definice\n",
    "\n",
    "# zas to jen zkoušíme (optional)\n",
    "output3 = pool(output2)\n",
    "print(f\"Shape po max pooling: {output3.shape}\")\n",
    "\n",
    "# vočíhneme vobrázek\n",
    "plt.imshow(output3[0, 2, :, :].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Po konvoluci: torch.Size([20, 9, 28, 28])\n",
      "Po ReLu: torch.Size([20, 9, 28, 28])\n",
      "Po max pooling: torch.Size([20, 9, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "# KONTROLY SHAPU \n",
    "# s relu neztrácíme dimenzi (output1 a output2 jsou stejné), ale s max pooling jo\n",
    "\n",
    "print(f\"Po konvoluci: {output1.shape}\")\n",
    "print(f\"Po ReLu: {output2.shape}\")\n",
    "print(f\"Po max pooling: {output3.shape}\")   # max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mám jen jednu convoluci, takže už jdeme dělat flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape po flatten: torch.Size([20, 1764])\n"
     ]
    }
   ],
   "source": [
    "# FLATTEN - tohle není definice, ale čekuju, že funguje\n",
    "flattened_output = output3.view(output3.size(0), -1)\n",
    "print(f\"Shape po flatten: {flattened_output.shape}\") \n",
    "\n",
    "# měl by vyjít tensor: [počet obrázků, zbytek parametrů]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LINEÁRNÍ TRANSFORMACE**\n",
    "\n",
    "`linear = nn.Linear` (resolution po max pooling * resolution po max pooling * počet pásem, počet tříd ke klasifikaci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeden velkej dlouhej vošklivej tensor: tensor([[ 0.2078, -0.1136, -0.1663],\n",
      "        [ 0.2340,  0.1156, -0.2979],\n",
      "        [ 0.0571, -0.0476, -0.2346],\n",
      "        [ 0.0292, -0.0850, -0.1453],\n",
      "        [ 0.1830,  0.0867, -0.2398],\n",
      "        [ 0.1337,  0.0174, -0.3431],\n",
      "        [ 0.1358,  0.0142, -0.2652],\n",
      "        [ 0.0923, -0.0204, -0.3130],\n",
      "        [ 0.1039, -0.0521, -0.2396],\n",
      "        [ 0.1003, -0.1911, -0.2545],\n",
      "        [ 0.0438, -0.0517, -0.2659],\n",
      "        [-0.0333, -0.1228, -0.1925],\n",
      "        [ 0.1075,  0.0028, -0.3450],\n",
      "        [ 0.1017,  0.0637, -0.2739],\n",
      "        [ 0.1077, -0.0138, -0.1893],\n",
      "        [ 0.2521,  0.0094,  0.1079],\n",
      "        [ 0.2602, -0.0623, -0.0337],\n",
      "        [ 0.1343, -0.0600, -0.2450],\n",
      "        [ 0.2012, -0.0104, -0.3766],\n",
      "        [ 0.2194, -0.0777, -0.3290]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# LINEÁRNÍ TRANSFORMACE (aplikuju na output z flatten)\n",
    "linear = nn.Linear(14*14*9, 3)  # první číslo je, že se to musí vejít do nějaké size, která odpovídá matici m a to druhý číslo je počet klasifikovaných tříd na výstupu\n",
    "out_fc = linear(flattened_output)\n",
    "print(f\"Jeden velkej dlouhej vošklivej tensor: {out_fc}\")   # ty pásma se seřadí za sebou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "takže tohle celý bylo pro srandu králíkům a teď the real stuff (ale jakoby tu srandu nejde přeskočit, protože musíš dělat to data exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (short version but not really)\n",
    "nic tady nekontroluju, je to dost o modlení a o štěstí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([20, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# přeuložíme si data do jiné proměnné\n",
    "x =X[:, :, :, :]\n",
    "print(f\"x shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TADY TESTUJEME ZNOVU, abychom byli 100% sure, že to funguje\n",
    "\n",
    "# definitions (inicializace)\n",
    "conv1 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1) \n",
    "relu1 = nn.ReLU()\n",
    "npool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# another definitions\n",
    "conv2 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1) \n",
    "relu2 = nn.ReLU()\n",
    "npool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# předefinujeme si i lineární transformaci\n",
    "linear1 = nn.Linear(128*7*7, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: torch.Size([20, 128, 7, 7])\n",
      "out_flat: torch.Size([20, 6272])\n",
      "out_cls: torch.Size([20, 3])\n"
     ]
    }
   ],
   "source": [
    "# DALŠÍ INICIALIZACE kde aplikuju tu předtím\n",
    "\n",
    "# forward\n",
    "out = conv1(x)\n",
    "out = relu1(out)\n",
    "out = npool1(out)\n",
    "\n",
    "# forward again\n",
    "out = conv2(out)\n",
    "out = relu2(out)\n",
    "out = npool2(out)\n",
    "\n",
    "# flattened output\n",
    "out_flat = out.view(out.size(0), -1)\n",
    "print(f\"out: {out.shape}\") \n",
    "print(f\"out_flat: {out_flat.shape}\")  \n",
    "\n",
    "# classification output\n",
    "out_cls = linear1(out_flat)\n",
    "print(f\"out_cls: {out_cls.shape}\") # vyjde mi [počet obrázků, počet klasifikačních tříd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funguje ti to? good job, teď na to teprve pustíš ten CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model - inicializujeme ho\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1) \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.npool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1) \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.npool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.linear1 = nn.Linear(128*7*7, 3)   \n",
    "\n",
    "\n",
    "    def forward(self, x):   \n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.npool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.npool2(out)\n",
    "        out_flat = out.view(out.size(0), -1)\n",
    "        out_cls = self.linear1(out_flat)\n",
    "\n",
    "        return out_cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTOVÁNÍ MODELU\n",
    "model = CNNModel(num_channels=1)    # num channels je, že mám jedno pásmo\n",
    "\n",
    "#model   # printne ty parametry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INICIALIZACE loss function\n",
    "criteria = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nastav learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# inicializiace optimizeru \n",
    "omptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hurá, jdeme TRÉNOVAT MODEL\n",
    "\n",
    "(prostě Ctrl+C a Ctrl+V bestie, don't overthink it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandu\\AppData\\Local\\Temp\\ipykernel_18552\\3824615364.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = criteria(outputs, torch.tensor(y_l, dtype = torch.long))\n",
      "C:\\Users\\vandu\\AppData\\Local\\Temp\\ipykernel_18552\\3824615364.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = criteria(output, torch.tensor(y_l, dtype = torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.0815908908843994 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1273126602172852 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1032081842422485 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1038635969161987 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1176170110702515 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1234979629516602 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.122855544090271 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.0333733558654785 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1287506818771362 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.0620125532150269 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1903636455535889 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1155636310577393 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.086115837097168 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1602437496185303 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1196578741073608 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.0878355503082275 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1021772623062134 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1522407531738281 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.0345557928085327 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.143305778503418 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.1149002313613892 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.0615277290344238 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.0266050100326538 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.0697457790374756 \n",
      "Epoch: 0  Train Loss: 1.1216962337493896 - Test Loss 1.152599573135376 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0828349590301514 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0639654397964478 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0824511051177979 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0676422119140625 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.084029197692871 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0879303216934204 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0696738958358765 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0558478832244873 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0724835395812988 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0538562536239624 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.1114877462387085 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0925792455673218 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0835886001586914 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.065765142440796 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.119734764099121 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0344096422195435 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.096122145652771 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0725210905075073 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.045823335647583 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0835622549057007 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.053288459777832 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0167487859725952 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.090512752532959 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0939171314239502 \n",
      "Epoch: 1  Train Loss: 1.1285250186920166 - Test Loss 1.0811172723770142 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.081446886062622 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0929867029190063 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0021932125091553 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.072853684425354 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0512052774429321 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.020857572555542 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0776458978652954 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0732080936431885 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0919009447097778 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0569467544555664 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0748673677444458 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0583678483963013 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0662338733673096 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.1020305156707764 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0357520580291748 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0694341659545898 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0807613134384155 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0261375904083252 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0583258867263794 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0880019664764404 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.1296889781951904 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0177226066589355 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.1320306062698364 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0172450542449951 \n",
      "Epoch: 2  Train Loss: 1.0767428874969482 - Test Loss 1.0417454242706299 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.075457215309143 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0623663663864136 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0300428867340088 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0720586776733398 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0613155364990234 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0962635278701782 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 0.9936763048171997 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 0.9861835241317749 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.1062531471252441 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 0.9430195093154907 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.06857430934906 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.1951587200164795 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.1013848781585693 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.05068039894104 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0168218612670898 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.084289312362671 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0506473779678345 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.1081560850143433 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0490131378173828 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0999921560287476 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0899114608764648 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 0.9124321937561035 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0155985355377197 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0783424377441406 \n",
      "Epoch: 3  Train Loss: 1.0624192953109741 - Test Loss 1.0969178676605225 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.1921865940093994 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.0121557712554932 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.0811842679977417 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 0.9677335619926453 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.140578031539917 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.1230332851409912 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.100589394569397 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 0.9800241589546204 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.0870884656906128 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.1601396799087524 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.1321136951446533 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.11431086063385 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.1740188598632812 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 0.9738714098930359 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.1442131996154785 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.1749346256256104 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.192647099494934 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.1723157167434692 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 0.9173274040222168 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 0.7466288208961487 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.0539945363998413 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 0.9894259572029114 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.239187479019165 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 0.9912746548652649 \n",
      "Epoch: 4  Train Loss: 0.8614991307258606 - Test Loss 1.1638765335083008 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9339339137077332 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 1.0397143363952637 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9003497362136841 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 1.0141125917434692 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9431082606315613 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9636710286140442 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9074110984802246 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.883047878742218 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 1.044797658920288 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9163812398910522 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 1.0206153392791748 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9414035081863403 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9348651766777039 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.8889603614807129 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.8862355947494507 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.8972349166870117 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 1.0308399200439453 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 1.0373108386993408 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 1.018022060394287 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 1.001483678817749 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9847449064254761 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9494787454605103 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9294893145561218 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9653177261352539 \n",
      "Epoch: 5  Train Loss: 0.9481649398803711 - Test Loss 0.9253748059272766 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 1.15695321559906 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 1.0144853591918945 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.9516133069992065 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.8733817934989929 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.839441180229187 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.8033669590950012 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.7954606413841248 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 1.2053945064544678 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.8385031819343567 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.9858618974685669 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.8486658334732056 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 1.0191973447799683 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.8814460039138794 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 1.1821997165679932 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.8751991391181946 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.8589092493057251 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 1.0913444757461548 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 1.0540969371795654 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.8352228999137878 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 1.1693265438079834 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.9081887006759644 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 1.0286452770233154 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 0.9618203043937683 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 1.0860326290130615 \n",
      "Epoch: 6  Train Loss: 0.8184504508972168 - Test Loss 1.0625653266906738 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.9245797395706177 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.8155392408370972 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.8440037965774536 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.912734866142273 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.8515031933784485 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.9338346719741821 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 1.0391827821731567 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.9595428705215454 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 1.0657684803009033 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.9793036580085754 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 1.008739709854126 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.8942734599113464 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.7786887884140015 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.8560115694999695 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.9168878793716431 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.9262394905090332 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.8867782354354858 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.8647268414497375 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.9640328288078308 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.967542290687561 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.9640568494796753 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.99615877866745 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.9728044271469116 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.8994642496109009 \n",
      "Epoch: 7  Train Loss: 0.8566234707832336 - Test Loss 0.8630760312080383 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.8937338590621948 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9073208570480347 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9273154139518738 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.8575299978256226 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9093166589736938 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.8330622911453247 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9881430864334106 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9339027404785156 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.7955476641654968 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.922400176525116 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9036059379577637 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9092676043510437 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9168427586555481 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 1.0136324167251587 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9708728790283203 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.8210529088973999 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.8655311465263367 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9053651094436646 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9422101974487305 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9846065640449524 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.8555418848991394 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 1.0050394535064697 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.8876843452453613 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.8708565831184387 \n",
      "Epoch: 8  Train Loss: 0.8933984041213989 - Test Loss 0.9478632807731628 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.7221670746803284 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.8072293400764465 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.6723904609680176 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.7130250930786133 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.8348557353019714 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.6752822995185852 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.867863655090332 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.8807908892631531 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.8588052988052368 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.776072084903717 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.9285528063774109 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 1.163425326347351 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.8965510129928589 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.882300078868866 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.7067081928253174 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.8460335731506348 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.5861742496490479 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.8189111948013306 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.7456863522529602 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 1.0263638496398926 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.8367988467216492 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.6176431179046631 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.837012767791748 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.9064643979072571 \n",
      "Epoch: 9  Train Loss: 0.6194659471511841 - Test Loss 0.6846495270729065 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.7704432606697083 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.468447744846344 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.7131089568138123 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.8271519541740417 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.7173676490783691 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.667573094367981 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.7292466163635254 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.7977141737937927 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.6240290403366089 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.5968118906021118 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.6023251414299011 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.5534923076629639 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.7133535146713257 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.6887263655662537 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.7736480236053467 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.5184709429740906 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.6752389073371887 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.7571478486061096 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.6844725608825684 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.5916787981987 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.6343114376068115 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.6395772099494934 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.681559681892395 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.6066322922706604 \n",
      "Epoch: 10  Train Loss: 0.5502590537071228 - Test Loss 0.7900944948196411 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.6375347375869751 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.7140437960624695 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.5617868304252625 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.7082942724227905 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.6013942360877991 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.48297977447509766 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.5784292221069336 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.6042118072509766 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.5029438138008118 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.494453102350235 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.4476783871650696 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.5142751932144165 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.6399441957473755 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.7844899892807007 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.6444805860519409 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.6629344820976257 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.42272132635116577 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.5010528564453125 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.6919174790382385 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.5352576971054077 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.5685549974441528 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.5969104170799255 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.44955915212631226 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.7508508563041687 \n",
      "Epoch: 11  Train Loss: 0.4500032961368561 - Test Loss 0.635707676410675 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.47814878821372986 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.6257548928260803 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.6742116212844849 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.6484454870223999 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.4562910497188568 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.5219250917434692 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.6328486800193787 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.5156759023666382 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.5563482642173767 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.6788593530654907 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.6611101031303406 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.4824146330356598 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.4980951249599457 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.6168851256370544 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.5793192982673645 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.7199404835700989 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.4301609396934509 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.5508619546890259 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.6248396039009094 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.4838697016239166 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.45390447974205017 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.6759886741638184 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.5728852152824402 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.5075948238372803 \n",
      "Epoch: 12  Train Loss: 0.47544074058532715 - Test Loss 0.5138958692550659 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.3790512681007385 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.5433517694473267 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.47891348600387573 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.6600106954574585 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.46012020111083984 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.49071240425109863 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.46856942772865295 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.4698755741119385 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.4187243580818176 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.6428122520446777 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.5880519151687622 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.3617098927497864 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.5944367051124573 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.8691776394844055 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.7251206636428833 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.5975781679153442 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.5150303244590759 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.5613896250724792 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.7392141222953796 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.5606886744499207 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.5041449069976807 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.5475959777832031 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.620714545249939 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.5724354982376099 \n",
      "Epoch: 13  Train Loss: 0.4289833903312683 - Test Loss 0.7109968662261963 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.5430344939231873 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.5443339347839355 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.4156127870082855 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.47169631719589233 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.6233538389205933 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.5740374326705933 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.7283802032470703 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.726291298866272 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.680295467376709 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.4902823865413666 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.2721041440963745 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.6809888482093811 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.4391704201698303 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.4076154828071594 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.4069121778011322 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.7244459390640259 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.5218892097473145 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.6677135229110718 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.6607909798622131 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.3909605145454407 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.3378981947898865 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.7001787424087524 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.5278223156929016 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.6014821529388428 \n",
      "Epoch: 14  Train Loss: 0.4245838522911072 - Test Loss 0.7491644620895386 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.28484898805618286 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.54931640625 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.3021431863307953 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.36589106917381287 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.47213831543922424 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.48380717635154724 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.5026089549064636 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.5131374597549438 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.4422082006931305 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.5107612013816833 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.3175601363182068 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.35148125886917114 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.4811568856239319 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.48930320143699646 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.3408038020133972 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.38323864340782166 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.5192743539810181 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.46007591485977173 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.3931991457939148 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.434806764125824 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.3747982680797577 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.3619807958602905 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.5017713904380798 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.44197559356689453 \n",
      "Epoch: 15  Train Loss: 0.42600902915000916 - Test Loss 0.4280780851840973 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.3131282925605774 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.25928497314453125 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.38963955640792847 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.40312638878822327 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.3216133117675781 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.4877799153327942 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.47309184074401855 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.363898903131485 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.40869826078414917 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.3522351384162903 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.44303998351097107 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.4835643768310547 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.30417269468307495 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.44936370849609375 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.31369560956954956 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.4660865366458893 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.47981947660446167 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.25562116503715515 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.4307660162448883 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.2737307846546173 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.4454565942287445 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.4151306748390198 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.42792758345603943 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.489175409078598 \n",
      "Epoch: 16  Train Loss: 0.4563252031803131 - Test Loss 0.4441812038421631 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.3919724225997925 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.6117095947265625 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.4169505536556244 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.29436811804771423 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.5173120498657227 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.38794320821762085 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.6224803328514099 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.6626248955726624 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.5227597951889038 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.3798241913318634 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.42494040727615356 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.3264632821083069 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.605390191078186 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.4158882200717926 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.5917947292327881 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.2956606149673462 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.4365488886833191 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.3434697389602661 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.48590144515037537 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.46649664640426636 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.3353888690471649 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.4192667007446289 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.4532528817653656 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.4665280282497406 \n",
      "Epoch: 17  Train Loss: 0.41160279512405396 - Test Loss 0.6242133975028992 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.38500651717185974 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.5588546991348267 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.40498894453048706 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.6156391501426697 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.4327799379825592 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.567923903465271 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.35816025733947754 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.395001083612442 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.5610483288764954 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.45349493622779846 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.3863709568977356 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.243600532412529 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.5157500505447388 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.22015070915222168 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.5730956196784973 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.5015770196914673 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.5997059345245361 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.7125681042671204 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.5857964754104614 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.5817623734474182 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.6683048605918884 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.36414650082588196 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.2042781412601471 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.4016798138618469 \n",
      "Epoch: 18  Train Loss: 0.25980883836746216 - Test Loss 0.40646472573280334 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.2548038363456726 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.37702512741088867 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.27708888053894043 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.3935199975967407 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.3256913423538208 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.22616545855998993 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.27426138520240784 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.43363285064697266 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.41790327429771423 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.4918563961982727 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.33845284581184387 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.45050668716430664 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.356098473072052 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.23019401729106903 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.27829286456108093 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.29261165857315063 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.4206717014312744 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.44639986753463745 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.2992399334907532 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.4091770648956299 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.3962640166282654 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.37158316373825073 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.279547780752182 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.27554529905319214 \n",
      "Epoch: 19  Train Loss: 0.26795321702957153 - Test Loss 0.3886854350566864 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.3485044240951538 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.4734951853752136 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.25253626704216003 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.1772678941488266 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.35421881079673767 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.44154638051986694 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.4516386091709137 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.3475332260131836 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.5057030916213989 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.5028936266899109 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.6112976670265198 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.5221035480499268 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.2369653880596161 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.32245585322380066 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.3999512195587158 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.31512999534606934 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.4520651400089264 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.5293034315109253 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.21640868484973907 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.6644636988639832 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.21770863234996796 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.3048182427883148 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.24485063552856445 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.2831359803676605 \n",
      "Epoch: 20  Train Loss: 0.34301862120628357 - Test Loss 0.36876848340034485 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.1992173045873642 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.5001434087753296 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.3251965641975403 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.6141963005065918 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.3280349373817444 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.3762907385826111 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.29343706369400024 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.3083133101463318 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.5406063199043274 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.4966500401496887 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.4184211790561676 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.26596903800964355 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.3522028625011444 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.4719525873661041 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.30009374022483826 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.3236507177352905 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.30818063020706177 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.39994531869888306 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.49512115120887756 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.4016038775444031 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.48182326555252075 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.26908615231513977 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.3192627429962158 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.21729132533073425 \n",
      "Epoch: 21  Train Loss: 0.20907869935035706 - Test Loss 0.42171335220336914 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.27834954857826233 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.2676633596420288 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.3138241469860077 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.3042561411857605 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.2655549645423889 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.43488985300064087 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.2166277915239334 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.35701820254325867 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.39658039808273315 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.34092989563941956 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.1972263753414154 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.3568059802055359 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.24294331669807434 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.21706926822662354 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.2650607228279114 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.3427283763885498 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.2573471665382385 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.20896092057228088 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.359576553106308 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.2506764829158783 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.2654089331626892 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.2891179919242859 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.31713932752609253 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.4130992889404297 \n",
      "Epoch: 22  Train Loss: 0.18086455762386322 - Test Loss 0.3086884021759033 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.2042592316865921 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.23968324065208435 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.38389497995376587 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.3086773753166199 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.3820958733558655 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.18087491393089294 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.1948535144329071 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.36779892444610596 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.4200568199157715 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.29509297013282776 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.3768223226070404 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.24749083817005157 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.37285250425338745 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.33639976382255554 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.3553367257118225 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.2515919804573059 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.41035041213035583 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.11092372238636017 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.21965578198432922 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.18896640837192535 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.3240930438041687 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.45442479848861694 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.21051903069019318 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.32031288743019104 \n",
      "Epoch: 23  Train Loss: 0.3008314073085785 - Test Loss 0.24976852536201477 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.3806339502334595 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 0.9731238484382629 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 0.948023796081543 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.422856092453003 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.3086512088775635 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.6672515869140625 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 0.5209501385688782 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.4056211709976196 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.576334834098816 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.2818210124969482 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 0.7821234464645386 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.5223848819732666 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.4549709558486938 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.105368971824646 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.2489776611328125 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.7186658382415771 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.6312099695205688 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.0469343662261963 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 0.9596465229988098 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.8494068384170532 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.1037795543670654 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.1381919384002686 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.8207935094833374 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 0.5286024808883667 \n",
      "Epoch: 24  Train Loss: 1.1204626560211182 - Test Loss 1.700290322303772 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.27666252851486206 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.29540324211120605 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.17413923144340515 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.286929190158844 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.3673272132873535 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.25853869318962097 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.25529295206069946 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.2262689769268036 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.40793904662132263 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.3280928134918213 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.35959893465042114 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.29602089524269104 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.3263514041900635 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.36284956336021423 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.2599334120750427 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.2706127464771271 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.37613409757614136 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.20160964131355286 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.2746414542198181 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.24543854594230652 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.28571659326553345 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.41252341866493225 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.22309055924415588 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.3380139470100403 \n",
      "Epoch: 25  Train Loss: 0.08984038233757019 - Test Loss 0.41376152634620667 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.4102615416049957 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.16237030923366547 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.2625107765197754 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.4344671666622162 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.3533495366573334 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.30834516882896423 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.39058467745780945 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.35022011399269104 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.26354268193244934 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.1731022298336029 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.2451377809047699 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.21192629635334015 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.4678064286708832 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.17145021259784698 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.16386716067790985 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.533998966217041 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.4149788022041321 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.29038000106811523 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.3735714852809906 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.37480321526527405 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.2471921443939209 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.1883467733860016 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.42145562171936035 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.2742517590522766 \n",
      "Epoch: 26  Train Loss: 0.20245817303657532 - Test Loss 0.47973352670669556 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 2.4502007961273193 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.320682168006897 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.120069146156311 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.6930084228515625 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 0.7615343332290649 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 2.5650112628936768 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.0205481052398682 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.9775164127349854 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.5069196224212646 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.772613763809204 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 2.0365912914276123 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 2.3211395740509033 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.5793689489364624 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.5097721815109253 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.5057837963104248 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.8203872442245483 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.9475008249282837 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.1786881685256958 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 2.140101909637451 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.8781049251556396 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.1122839450836182 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 2.2207882404327393 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.2554423809051514 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 1.274888277053833 \n",
      "Epoch: 27  Train Loss: 1.6191412210464478 - Test Loss 2.1355204582214355 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.2351592779159546 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.15465857088565826 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.18931379914283752 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.16949599981307983 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.2764226496219635 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.23831096291542053 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.1784026175737381 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.20299871265888214 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.2566804885864258 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.22305206954479218 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.1644364595413208 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.23256973922252655 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.21252214908599854 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.3736189901828766 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.3070327937602997 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.19390402734279633 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.2286119908094406 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.2701990306377411 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.23814889788627625 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.3842117190361023 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.34730032086372375 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.4007469117641449 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.270094096660614 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.31220248341560364 \n",
      "Epoch: 28  Train Loss: 0.3482024073600769 - Test Loss 0.18908309936523438 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 1.019718885421753 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.6116902828216553 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.705231249332428 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.44875675439834595 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.7777793407440186 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.5662281513214111 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.6910044550895691 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 1.126765489578247 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.9875465631484985 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.7778370976448059 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.5959357023239136 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.7041657567024231 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.8656856417655945 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.18609079718589783 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.6636582016944885 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.4668551981449127 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.8578699231147766 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.8107097744941711 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.3960697054862976 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.6957637667655945 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.46143442392349243 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.6270416975021362 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.4563036859035492 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.6768094301223755 \n",
      "Epoch: 29  Train Loss: 0.49253425002098083 - Test Loss 0.7441021800041199 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.20673882961273193 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.13497211039066315 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.26885050535202026 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.1710336059331894 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.24290911853313446 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.2177010476589203 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.1932888776063919 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.1814614236354828 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.2008495330810547 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.2708132266998291 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.18452878296375275 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.1548016518354416 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.2447691261768341 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.2537110447883606 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.14149975776672363 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.2142503708600998 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.21366386115550995 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.21491475403308868 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.14128461480140686 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.24200794100761414 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.2845868468284607 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.1994534730911255 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.311953067779541 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.15809887647628784 \n",
      "Epoch: 30  Train Loss: 0.18282108008861542 - Test Loss 0.2479545623064041 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.4863576292991638 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.39688798785209656 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.29718199372291565 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.22344811260700226 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.348287433385849 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.1669820249080658 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.2336411029100418 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.4214589595794678 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.2818836569786072 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.20333394408226013 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.18194647133350372 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.24270431697368622 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.4358274042606354 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.3922346532344818 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.43702617287635803 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.38236144185066223 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.5877217054367065 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.2767346203327179 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.21614941954612732 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.4660288393497467 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.44780635833740234 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.5025292038917542 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.2970293462276459 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.2658894956111908 \n",
      "Epoch: 31  Train Loss: 0.2730151414871216 - Test Loss 0.2775152325630188 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.7543994188308716 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.271995484828949 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.25308576226234436 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.32683512568473816 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.27214181423187256 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.20705802738666534 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.5125151872634888 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.42171645164489746 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.3299036920070648 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.2840278744697571 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.5620182156562805 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.3599826693534851 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.2542567849159241 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.24961502850055695 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.11824853718280792 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.3984488546848297 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.3246859014034271 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.28875401616096497 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.2907126545906067 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.374524861574173 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.4526694416999817 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.5068721771240234 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.44913262128829956 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.2912123501300812 \n",
      "Epoch: 32  Train Loss: 0.07143630087375641 - Test Loss 0.6869388818740845 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.12779244780540466 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.14028994739055634 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.2199210822582245 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.15024499595165253 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.21358339488506317 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.19244329631328583 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.1970532238483429 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.1597684770822525 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.25091540813446045 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.1706843227148056 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.13744942843914032 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.18603815138339996 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.20802953839302063 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.1956649124622345 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.23828370869159698 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.1299258917570114 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.2916894555091858 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.16842226684093475 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.13924556970596313 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.12518148124217987 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.19256070256233215 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.2039199322462082 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.23457899689674377 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.20532217621803284 \n",
      "Epoch: 33  Train Loss: 0.19245877861976624 - Test Loss 0.14870789647102356 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.24531972408294678 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.19930873811244965 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.14695075154304504 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.161003977060318 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.06795183569192886 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.2122879922389984 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.1058637723326683 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.17995184659957886 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.13276900351047516 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.15101172029972076 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.10679103434085846 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.18727508187294006 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.12007405608892441 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.2172103375196457 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.09009841084480286 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.14954039454460144 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.200879767537117 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.2586742043495178 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.1349942982196808 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.16157282888889313 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.19913294911384583 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.2611643075942993 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.11805794388055801 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.19123071432113647 \n",
      "Epoch: 34  Train Loss: 0.09902619570493698 - Test Loss 0.1393851786851883 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.2063472718000412 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.11730428785085678 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.13706550002098083 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.2271498143672943 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.11766707897186279 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.1498216688632965 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.1343136727809906 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.176362544298172 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.20212578773498535 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.10499091446399689 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.15822461247444153 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.2500354051589966 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.12300558388233185 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.16744181513786316 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.1250951737165451 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.10519243776798248 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.2118670642375946 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.16706305742263794 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.20105907320976257 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.2171824723482132 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.25083503127098083 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.17999699711799622 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.10300369560718536 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.14947015047073364 \n",
      "Epoch: 35  Train Loss: 0.15485791862010956 - Test Loss 0.14231617748737335 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.6573654413223267 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.9456781148910522 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.37511682510375977 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.4178024232387543 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.557371199131012 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.35794898867607117 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.4082642197608948 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.5827210545539856 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.6875835061073303 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.49683326482772827 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.4758402705192566 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.40695786476135254 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.6462498903274536 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.27863824367523193 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.38047319650650024 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.2841946482658386 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.42879408597946167 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.48483556509017944 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.35984963178634644 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.4676728844642639 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.6531920433044434 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.5912386178970337 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.36844682693481445 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.36039596796035767 \n",
      "Epoch: 36  Train Loss: 0.1950712502002716 - Test Loss 0.32196861505508423 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.23768556118011475 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.19155091047286987 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.5151732563972473 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.34541526436805725 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.27926105260849 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.16659128665924072 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.3983771502971649 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.17332938313484192 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.30255240201950073 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.2930065989494324 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.3377121388912201 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.2885715365409851 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.2466491162776947 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.2273516207933426 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.2463769167661667 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.17899592220783234 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.18363691866397858 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.24048876762390137 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.18311657011508942 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.2615390419960022 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.15558359026908875 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.40287572145462036 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.23673424124717712 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.28325533866882324 \n",
      "Epoch: 37  Train Loss: 0.17421641945838928 - Test Loss 0.29584428668022156 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.3790150582790375 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.2634836435317993 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.553782045841217 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.12892994284629822 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.24653403460979462 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.25831976532936096 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.29053568840026855 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.48909449577331543 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.16516296565532684 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.3667050004005432 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.24208524823188782 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.37381598353385925 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.252933144569397 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.43741244077682495 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.22941908240318298 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.292587012052536 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.15656915307044983 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.32644230127334595 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.09225872904062271 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.12351832538843155 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.28882017731666565 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.29716625809669495 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.217049241065979 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.27334219217300415 \n",
      "Epoch: 38  Train Loss: 0.11078796535730362 - Test Loss 0.5473231077194214 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.17010627686977386 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.22055964171886444 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.25270789861679077 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.17956283688545227 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.1139705553650856 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.1184588074684143 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.11986404657363892 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.17622525990009308 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.10436487197875977 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.11709417402744293 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.1507764607667923 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.1686960905790329 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.13427071273326874 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.1007949560880661 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.17541101574897766 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.13445691764354706 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.15634241700172424 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.21627280116081238 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.14683052897453308 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.1680079698562622 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.13978485763072968 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.1523740291595459 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.1378532350063324 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.13757288455963135 \n",
      "Epoch: 39  Train Loss: 0.10444667190313339 - Test Loss 0.11850623041391373 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.10286154597997665 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.09675464779138565 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.08727304637432098 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.086149200797081 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.05737021565437317 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.09900426119565964 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.1623990535736084 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.10023906081914902 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.1477094143629074 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.1374281793832779 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.09931506216526031 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.0986267700791359 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.09890899807214737 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.24074435234069824 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.09256252646446228 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.06614522635936737 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.23361384868621826 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.2092660367488861 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.19781586527824402 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.12158951908349991 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.10460086166858673 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.12639722228050232 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.13162674009799957 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.09176809340715408 \n",
      "Epoch: 40  Train Loss: 0.05623061582446098 - Test Loss 0.16955627501010895 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.6293627023696899 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.2714884281158447 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.23169906437397003 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.37564390897750854 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.3280845284461975 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.26035282015800476 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.16257628798484802 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.35498782992362976 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.2037886381149292 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.30747631192207336 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.3549879789352417 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.6276127099990845 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.40433916449546814 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.6680688858032227 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.3460363745689392 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.22358226776123047 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.27262669801712036 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.3182089924812317 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.18408283591270447 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.4935532510280609 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.38418489694595337 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.3673315644264221 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.19042110443115234 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.18339885771274567 \n",
      "Epoch: 41  Train Loss: 1.0071032047271729 - Test Loss 0.07020486891269684 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.16173811256885529 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.11866460740566254 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.16070953011512756 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.2441747635602951 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.13615640997886658 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.25651782751083374 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.3676343560218811 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.05173482745885849 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.2001611292362213 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.28459328413009644 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.453136146068573 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.10852718353271484 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.24415583908557892 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.07612685114145279 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.21474869549274445 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.332293838262558 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.09563963860273361 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.3669234812259674 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.3578934073448181 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.18788832426071167 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.2764587104320526 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.19256247580051422 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.09729050099849701 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.2317674160003662 \n",
      "Epoch: 42  Train Loss: 0.17864851653575897 - Test Loss 0.30506277084350586 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.2836700975894928 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.11460074037313461 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.19741761684417725 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.2176603376865387 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.2270926535129547 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.18546167016029358 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.12076027691364288 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.14488789439201355 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.26982182264328003 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.25153616070747375 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.2450782060623169 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.21663308143615723 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.22745196521282196 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.11786822229623795 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.09166962653398514 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.20669929683208466 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.15172313153743744 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.19920869171619415 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.0489717498421669 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.2519523501396179 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.1449248045682907 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.14609098434448242 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.05646552890539169 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.06719030439853668 \n",
      "Epoch: 43  Train Loss: 0.14869600534439087 - Test Loss 0.22796082496643066 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.09168819338083267 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.06767178326845169 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.044722385704517365 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.21912381052970886 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.06750960648059845 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.10351179540157318 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.13902117311954498 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.13272596895694733 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.09885583072900772 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.15808627009391785 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.09939129650592804 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.14757926762104034 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.09123264998197556 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.12533879280090332 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.05335106700658798 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.11555298417806625 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.13777554035186768 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.23063591122627258 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.11679716408252716 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.16157570481300354 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.1677282154560089 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.06917186081409454 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.11499879509210587 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.08065535128116608 \n",
      "Epoch: 44  Train Loss: 0.090921550989151 - Test Loss 0.09763143211603165 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.09997199475765228 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.12064893543720245 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.08741453289985657 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.10736755281686783 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.08395150303840637 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.10462319850921631 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.055074431002140045 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.06841011345386505 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.06149871274828911 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.05252950266003609 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.14367547631263733 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.19490887224674225 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.1302567571401596 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.16897760331630707 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.09330976754426956 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.17469951510429382 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.06376668065786362 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.06785964220762253 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.07961996644735336 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.08407740294933319 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.12680736184120178 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.198410764336586 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.07879309356212616 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.18251167237758636 \n",
      "Epoch: 45  Train Loss: 0.14707836508750916 - Test Loss 0.12485446780920029 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.13374626636505127 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.1440737545490265 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.116668701171875 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.050520092248916626 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.1420379877090454 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.09912875294685364 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.260288268327713 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.18031170964241028 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.18882380425930023 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.09086563438177109 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.14153803884983063 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.14472611248493195 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.13638994097709656 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.08680517971515656 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.08595366775989532 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.12016221135854721 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.15530605614185333 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.18961788713932037 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.12951496243476868 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.1331653892993927 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.13254114985466003 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.04850775748491287 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.13275554776191711 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.25706636905670166 \n",
      "Epoch: 46  Train Loss: 0.05984685942530632 - Test Loss 0.04468831419944763 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.11060614883899689 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.0840156227350235 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.12000329792499542 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.14293187856674194 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.05942339822649956 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.15964439511299133 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.11938101053237915 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.0854797437787056 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.1920681893825531 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.10042931139469147 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.08403297513723373 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.24204964935779572 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.18256209790706635 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.1205938458442688 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.06424561142921448 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.14453719556331635 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.13463200628757477 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.10955725610256195 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.19913068413734436 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.08022694289684296 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.14595858752727509 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.0904785767197609 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.07278208434581757 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.11918710172176361 \n",
      "Epoch: 47  Train Loss: 0.9288215637207031 - Test Loss 0.15049132704734802 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.07606278359889984 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.11540070921182632 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.080446258187294 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.22617781162261963 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.08817074447870255 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.06597989052534103 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.1086539477109909 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.069932721555233 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.10181460529565811 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.044065721333026886 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.04677809402346611 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.09221187233924866 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.09934967011213303 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.1017172783613205 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.05991504713892937 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.15016473829746246 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.3372054994106293 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.11201195418834686 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.07465900480747223 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.08357522636651993 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.17861148715019226 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.09408117830753326 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.1372501254081726 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.185550719499588 \n",
      "Epoch: 48  Train Loss: 0.07159730792045593 - Test Loss 0.057309966534376144 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.036887139081954956 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.1278732717037201 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.08379673957824707 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.09805278480052948 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.11651992797851562 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.02976332977414131 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.07657182961702347 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.16886302828788757 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.07413884252309799 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.1724538505077362 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.09365919232368469 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.09884031862020493 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.1164775937795639 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.14647088944911957 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.08438871800899506 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.1520749032497406 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.07519606500864029 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.13035348057746887 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.062691330909729 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.17411090433597565 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.030719568952918053 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.07057304680347443 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.12187916040420532 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.08919486403465271 \n",
      "Epoch: 49  Train Loss: 0.055516742169857025 - Test Loss 0.020192362368106842 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.0362846776843071 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.1472131460905075 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.05842110514640808 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.07413832098245621 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.2101740539073944 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.11880328506231308 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.1982746720314026 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.21974515914916992 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.15272179245948792 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.08242771774530411 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.05552220344543457 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.1381739228963852 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.04612601548433304 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.05154978483915329 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.10954034328460693 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.0359758660197258 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.08362146466970444 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.2119048833847046 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.06815062463283539 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.0672837644815445 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.08173034340143204 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.0795857384800911 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.09231279790401459 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.051454830914735794 \n",
      "Epoch: 50  Train Loss: 0.08816821873188019 - Test Loss 0.06233545020222664 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.2623048722743988 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.10607737302780151 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.11556114256381989 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.07563986629247665 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.07295886427164078 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.05503588914871216 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.048605483025312424 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.06704920530319214 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.05597870424389839 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.05307566374540329 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.08176729828119278 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.07597501575946808 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.06502113491296768 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.028888139873743057 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.17449580132961273 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.11998679488897324 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.09162165224552155 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.04690466448664665 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.13004332780838013 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.07257720082998276 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.09033887088298798 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.15891918540000916 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.036303743720054626 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.10383890569210052 \n",
      "Epoch: 51  Train Loss: 0.06314437836408615 - Test Loss 0.12408008426427841 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.14246313273906708 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.1039051041007042 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.09343291819095612 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.12797412276268005 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.13277485966682434 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.1801832914352417 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.07670556753873825 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.08281819522380829 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.14228938519954681 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.1634056568145752 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.06786002218723297 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.07525786757469177 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.08609028160572052 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.1097998172044754 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.10233700275421143 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.18381521105766296 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.18052232265472412 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.10829484462738037 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.09470312297344208 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.09791092574596405 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.22149601578712463 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.10514150559902191 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.1576811969280243 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.14110268652439117 \n",
      "Epoch: 52  Train Loss: 0.15738758444786072 - Test Loss 0.12027591466903687 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.08697383850812912 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.10612555593252182 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.15866637229919434 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.06386739015579224 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.09544827044010162 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.02867387793958187 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.08610747754573822 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.07370807230472565 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.07466406375169754 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.08581866323947906 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.054926492273807526 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.0676836222410202 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.04584416002035141 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.08229979127645493 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.0962560623884201 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.10484107583761215 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.11508826911449432 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.11257137358188629 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.030698170885443687 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.044469017535448074 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.09980037063360214 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.13182127475738525 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.1542086899280548 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.047596972435712814 \n",
      "Epoch: 53  Train Loss: 0.033693015575408936 - Test Loss 0.13778220117092133 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.0468594953417778 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.14935196936130524 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.041438017040491104 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.06901191174983978 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.08128248900175095 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.07935919612646103 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.10460475832223892 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.09633832424879074 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.1585886925458908 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.10352025181055069 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.033569466322660446 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.03761487826704979 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.07784177362918854 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.03845756873488426 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.06452210247516632 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.15189315378665924 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.040962524712085724 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.07582331448793411 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.1263391077518463 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.059590138494968414 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.042758625000715256 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.06136564537882805 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.060909759253263474 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.07368888705968857 \n",
      "Epoch: 54  Train Loss: 0.02171054668724537 - Test Loss 0.07802946865558624 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.12487391382455826 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.06695807725191116 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.13654029369354248 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.10054834932088852 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.23161408305168152 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.043015144765377045 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.18920756876468658 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.053572915494441986 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.279544472694397 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.27910375595092773 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.07339301705360413 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.10041661560535431 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.04572572186589241 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.09672693908214569 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.056485652923583984 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.1004258245229721 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.14397823810577393 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.06947948038578033 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.04901996999979019 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.13185635209083557 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.05896685644984245 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.0766192376613617 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.20626814663410187 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.027718815952539444 \n",
      "Epoch: 55  Train Loss: 0.09567296504974365 - Test Loss 0.12128492444753647 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.11233849823474884 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.1482725292444229 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.13611961901187897 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.16318809986114502 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.14190137386322021 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.24762630462646484 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.5175145864486694 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.034825462847948074 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.1365802139043808 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.16454368829727173 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.11241175979375839 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.17061392962932587 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.043962493538856506 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.2483348399400711 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.3185306787490845 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.19351133704185486 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.34263062477111816 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.4770503044128418 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.21657522022724152 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.07299111783504486 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.03493596985936165 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.18630599975585938 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.5044070482254028 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.06434004008769989 \n",
      "Epoch: 56  Train Loss: 0.12327621877193451 - Test Loss 0.18423208594322205 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.19655033946037292 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.25102588534355164 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.14025773108005524 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.17522583901882172 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.25757554173469543 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.19348224997520447 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.23804345726966858 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.35887411236763 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.20671972632408142 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.22821292281150818 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.1673661321401596 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.08286932110786438 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.22221413254737854 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.23584194481372833 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.29011669754981995 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.25882628560066223 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.21812379360198975 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.06298909336328506 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.1540069580078125 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.12717971205711365 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.11958727985620499 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.25736433267593384 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.16532748937606812 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.1707441508769989 \n",
      "Epoch: 57  Train Loss: 0.12092161178588867 - Test Loss 0.22791969776153564 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.04281853884458542 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.16699543595314026 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.0737154558300972 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.11312659829854965 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.06395326554775238 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.045622389763593674 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.054093390703201294 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.06170463562011719 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.08989787101745605 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.060478441417217255 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.04676329717040062 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.0481400266289711 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.043755464255809784 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.09187605232000351 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.1296195685863495 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.11949887126684189 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.08690167963504791 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.14387179911136627 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.14941909909248352 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.12488611787557602 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.12675021588802338 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.08895224332809448 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.07299662381410599 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.10560697317123413 \n",
      "Epoch: 58  Train Loss: 0.041873298585414886 - Test Loss 0.09835617244243622 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.09075035154819489 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.05535604804754257 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.06320615112781525 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.12179304659366608 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.060245364904403687 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.07428997755050659 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.04126641899347305 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.07826769351959229 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.033951930701732635 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.03815818205475807 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.11101527512073517 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.1902408003807068 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.08047230541706085 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.05482994765043259 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.16700612008571625 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.2199876755475998 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.1290062963962555 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.13504278659820557 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.12075009196996689 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.07518671452999115 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.04854939132928848 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.08448156714439392 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.1153767853975296 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.16039052605628967 \n",
      "Epoch: 59  Train Loss: 0.040536269545555115 - Test Loss 0.07778768986463547 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.1167161613702774 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.14095935225486755 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.06518285721540451 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.06500294804573059 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.08719851076602936 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.06661666929721832 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.21949121356010437 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.07446493208408356 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.11615538597106934 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.10337463766336441 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.07530700415372849 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.11714448034763336 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.11209879070520401 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.22326692938804626 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.05748448520898819 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.06548455357551575 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.12105830013751984 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.0744573250412941 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.07434992492198944 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.07202614843845367 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.15126584470272064 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.09511589258909225 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.13592937588691711 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.10022081434726715 \n",
      "Epoch: 60  Train Loss: 0.05074087902903557 - Test Loss 0.09399773180484772 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.04525027424097061 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.09964364022016525 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.16509707272052765 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.10971387475728989 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.1594943255186081 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.10335002094507217 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.11738824844360352 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.03629051521420479 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.18999069929122925 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.17893894016742706 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.09182064980268478 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.19642184674739838 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.1568971574306488 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.15449637174606323 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.0513182170689106 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.11206527799367905 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.04735865443944931 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.11556756496429443 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.11683084815740585 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.15362951159477234 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.14253778755664825 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.0971875712275505 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.09766849130392075 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.21238979697227478 \n",
      "Epoch: 61  Train Loss: 0.04104152321815491 - Test Loss 0.13748005032539368 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.04373302310705185 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.06607581675052643 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.07145698368549347 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.096385158598423 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.11055666208267212 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.2035757303237915 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.048024214804172516 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.05540536716580391 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.06104888767004013 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.052149832248687744 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.10501863062381744 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.030622318387031555 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.025223154574632645 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.05261310189962387 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.15335199236869812 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.08814473450183868 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.03403245285153389 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.2236267775297165 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.10413016378879547 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.15023194253444672 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.028879720717668533 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.09343861043453217 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.05747203156352043 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.04449111968278885 \n",
      "Epoch: 62  Train Loss: 0.05632100626826286 - Test Loss 0.0605204701423645 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.03290068358182907 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.05348150059580803 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.09740099310874939 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.12020552158355713 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.05007116124033928 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.010437733493745327 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.055332232266664505 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.1322670876979828 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.08030197769403458 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.09047864377498627 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.10444475710391998 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.05054279416799545 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.08464168757200241 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.041715092957019806 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.06955958157777786 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.11081542074680328 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.06664752960205078 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.030393917113542557 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.06192261725664139 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.05644151568412781 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.048963434994220734 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.05521177127957344 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.14484503865242004 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.23798668384552002 \n",
      "Epoch: 63  Train Loss: 0.03923957794904709 - Test Loss 0.038399066776037216 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.06385508924722672 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.027623597532510757 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.03786041587591171 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.06064491346478462 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.07858841866254807 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.056368373334407806 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.04685557633638382 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.03291941061615944 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.12308983504772186 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.038763921707868576 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.16219691932201385 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.03709445893764496 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.0339258536696434 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.07021567225456238 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.0850212424993515 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.21305115520954132 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.08159434050321579 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.080865778028965 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.08173342049121857 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.1321125626564026 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.07799563556909561 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.030828123912215233 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.09673265367746353 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.05671694874763489 \n",
      "Epoch: 64  Train Loss: 0.026784908026456833 - Test Loss 0.05858445167541504 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.06191467493772507 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.06852935254573822 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.05533900856971741 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.08017618954181671 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.2433699667453766 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.09517787396907806 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.05596401169896126 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.04635581001639366 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.04934728145599365 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.02137042209506035 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.10198967158794403 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.035271644592285156 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.0716700404882431 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.031045639887452126 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.11044061183929443 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.04148150235414505 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.1188078299164772 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.08572427928447723 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.04102402180433273 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.05112870782613754 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.06208254024386406 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.15230906009674072 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.08619584143161774 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.12045969069004059 \n",
      "Epoch: 65  Train Loss: 0.060875050723552704 - Test Loss 0.042127784341573715 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.032116785645484924 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.096788689494133 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.05061432719230652 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.03277922049164772 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.030427521094679832 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.03607628121972084 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.049043916165828705 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.05271544307470322 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.024354837834835052 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.013551945798099041 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.07535231858491898 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.14922495186328888 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.023008108139038086 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.08478071540594101 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.02595633640885353 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.06262482702732086 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.12177480757236481 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.031912945210933685 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.10879351198673248 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.14409421384334564 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.059214603155851364 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.040176209062337875 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.2433158904314041 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.060274265706539154 \n",
      "Epoch: 66  Train Loss: 0.012390226125717163 - Test Loss 0.04574529826641083 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.12300848960876465 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.08222897350788116 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.05649103596806526 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.08411968499422073 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.08225127309560776 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.05842209607362747 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.10394402593374252 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.12032312154769897 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.12129276990890503 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.03339638561010361 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.03429197892546654 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.14766892790794373 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.07307010143995285 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.042073268443346024 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.07400266826152802 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.06456228345632553 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.04414556920528412 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.04393608123064041 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.07166207581758499 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.0719827264547348 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.09837811440229416 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.0831567794084549 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.07158862799406052 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.06345603615045547 \n",
      "Epoch: 67  Train Loss: 0.022046569734811783 - Test Loss 0.07215418666601181 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.10618039220571518 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.11529967933893204 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.030242064967751503 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.11831685155630112 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.050599366426467896 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.061738330870866776 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.02992147207260132 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.018269335851073265 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.1486542671918869 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.06837452203035355 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.039946191012859344 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.0707169622182846 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.021844778209924698 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.06878696382045746 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.07021123915910721 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.02046491578221321 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.12301468849182129 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.01643666997551918 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.06705200672149658 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.07566581666469574 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.08458314836025238 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.1025102287530899 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.0312746986746788 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.11945845186710358 \n",
      "Epoch: 68  Train Loss: 0.028681229799985886 - Test Loss 0.03043709322810173 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.02891531027853489 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.07807063311338425 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.04179130122065544 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.04926279932260513 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.044276945292949677 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.024865727871656418 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.10493602603673935 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.04932310804724693 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.018501097336411476 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.17342990636825562 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.01964757591485977 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.2007146179676056 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.02458975836634636 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.1522919237613678 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.018914740532636642 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.04388618469238281 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.06221519038081169 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.12567833065986633 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.021554231643676758 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.06458412110805511 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.08746785670518875 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.03586946800351143 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.04310186952352524 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.10547289997339249 \n",
      "Epoch: 69  Train Loss: 0.03733161464333534 - Test Loss 0.025834372267127037 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.2510891556739807 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.22234952449798584 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.15363562107086182 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.3283945322036743 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.1404610276222229 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.11589892953634262 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.13662555813789368 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.20647859573364258 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.1573900580406189 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.10863828659057617 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.14732800424098969 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.17050066590309143 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.1757817417383194 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.1495070904493332 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.06359095126390457 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.2355760633945465 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.19107159972190857 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.15754184126853943 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.141933411359787 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.10862773656845093 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.12448029220104218 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.05229366943240166 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.030369332060217857 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.2588866353034973 \n",
      "Epoch: 70  Train Loss: 0.11440068483352661 - Test Loss 0.16713932156562805 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.04830820485949516 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.020257629454135895 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.02639257349073887 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.05107152462005615 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.04793495312333107 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.08728255331516266 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.061741333454847336 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.10360570251941681 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.268657922744751 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.06673315912485123 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.07036121189594269 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.03723427653312683 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.04310891777276993 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.038314659148454666 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.08709702640771866 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.0332234725356102 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.08641283214092255 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.041371092200279236 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.0631348118185997 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.07277953624725342 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.03073795698583126 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.014310918748378754 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.044095057994127274 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.04147522523999214 \n",
      "Epoch: 71  Train Loss: 0.015048814006149769 - Test Loss 0.023674018681049347 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.03507466986775398 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.011536472477018833 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.06149842217564583 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.09882713854312897 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.048731766641139984 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.10101030766963959 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.058719832450151443 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.2018980234861374 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.11222986876964569 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.023834217339754105 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.024238435551524162 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.16791363060474396 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.12214545160531998 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.08745624125003815 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.037855569273233414 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.03276899456977844 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.03265831619501114 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.02642359770834446 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.09250661730766296 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.12422354519367218 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.039960384368896484 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.04246591404080391 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.04992107301950455 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.037189967930316925 \n",
      "Epoch: 72  Train Loss: 0.019200455397367477 - Test Loss 0.04297393932938576 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.15098021924495697 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.15813109278678894 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.03366488963365555 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.06377926468849182 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.04695878550410271 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.11627153307199478 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.03979115188121796 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.013177704997360706 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.12314431369304657 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.06586875021457672 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.012486095540225506 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.047311797738075256 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.1160486489534378 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.22693786025047302 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.013970528729259968 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.09969300031661987 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.03500400111079216 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.13651235401630402 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.029065657407045364 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.026995548978447914 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.08134819567203522 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.030064096674323082 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.055841438472270966 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.0661659836769104 \n",
      "Epoch: 73  Train Loss: 0.03015344962477684 - Test Loss 0.06851311028003693 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.38807275891304016 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.46755489706993103 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.1474684774875641 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.2103348672389984 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.6042168736457825 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.48162803053855896 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.2647973299026489 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.31608903408050537 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.25742143392562866 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.39062872529029846 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.02802944742143154 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.6115854382514954 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.8326261639595032 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.4085372984409332 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.22802209854125977 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.1630881279706955 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.24144604802131653 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.05740675330162048 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.35812869668006897 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.2274981439113617 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.045456938445568085 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.1944025158882141 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.33303144574165344 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.2244764268398285 \n",
      "Epoch: 74  Train Loss: 0.2554776072502136 - Test Loss 0.13719847798347473 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.35761135816574097 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.556819498538971 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.6908757090568542 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.7330220937728882 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.6831755042076111 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.37937691807746887 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.3825291097164154 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.8532851934432983 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.46191802620887756 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.4893009066581726 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.6529577970504761 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.4972914159297943 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.42285460233688354 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.1981380432844162 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.48965612053871155 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.7183385491371155 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.6345523595809937 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.10150724649429321 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.13817118108272552 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.8685234785079956 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.5943730473518372 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.46655741333961487 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.7444433569908142 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 1.2143361568450928 \n",
      "Epoch: 75  Train Loss: 0.30769723653793335 - Test Loss 0.7037956118583679 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.046962615102529526 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.0457744337618351 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.20857477188110352 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.11575490236282349 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.11383410543203354 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.11711553484201431 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.07871268689632416 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.03370518237352371 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.06193473935127258 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.04733864217996597 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.07899152487516403 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.04538705199956894 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.14154654741287231 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.1371072381734848 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.044050153344869614 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.04929766803979874 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.06254246085882187 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.06143047660589218 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.07997436821460724 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.05611305311322212 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.23528611660003662 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.1331486701965332 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.04483754187822342 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.034493427723646164 \n",
      "Epoch: 76  Train Loss: 0.035285621881484985 - Test Loss 0.03137240558862686 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.03295672684907913 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.01996040903031826 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.12937936186790466 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.021869007498025894 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.034444235265254974 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.045067764818668365 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.0734093114733696 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.049510080367326736 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.047624506056308746 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.04747142642736435 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.12887965142726898 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.3895188271999359 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.12773433327674866 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.05782667547464371 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.09427002817392349 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.033413562923669815 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.028393426910042763 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.07710222899913788 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.0860699936747551 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.017864394932985306 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.03445278853178024 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.1518937647342682 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.025977563112974167 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.04748934507369995 \n",
      "Epoch: 77  Train Loss: 0.02180243283510208 - Test Loss 0.09045173227787018 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.12458014488220215 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.043319009244441986 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.02068258449435234 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.29444339871406555 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.057848621159791946 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.045210231095552444 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.03438790142536163 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.016374941915273666 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.09230603277683258 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.03657030686736107 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.12971170246601105 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.08604101091623306 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.04624815285205841 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.042928725481033325 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.03783506527543068 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.0673237070441246 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.0991021916270256 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.07734156399965286 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.02071918547153473 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.06272201240062714 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.04915284365415573 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.027139823883771896 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.06788875162601471 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.04094275087118149 \n",
      "Epoch: 78  Train Loss: 0.01797136291861534 - Test Loss 0.04737253859639168 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.035535551607608795 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.04709210246801376 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.07783802598714828 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.055989064276218414 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.05364527180790901 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.05262502282857895 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.04653587564826012 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.10059373080730438 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.03706563636660576 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.08602236211299896 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.07910999655723572 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.17826803028583527 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.16898073256015778 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.04393095523118973 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.06442421674728394 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.035922273993492126 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.022016216069459915 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.09642801433801651 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.05173212289810181 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.03490465134382248 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.12142568826675415 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.1148073822259903 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.09188146889209747 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.06268142908811569 \n",
      "Epoch: 79  Train Loss: 0.025144359096884727 - Test Loss 0.1633230745792389 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.04795209690928459 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.18437375128269196 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.13416963815689087 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.27103880047798157 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.1852889358997345 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.2444097101688385 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.4054771959781647 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.09413772821426392 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.15435148775577545 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.18028850853443146 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.07017716020345688 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.18470796942710876 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.24665796756744385 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.05856313556432724 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.04008454829454422 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.18846097588539124 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.11071030050516129 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.11439149081707001 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.20541727542877197 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.1496208906173706 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.20483286678791046 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.26959937810897827 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.15512536466121674 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.13905838131904602 \n",
      "Epoch: 80  Train Loss: 0.11235533654689789 - Test Loss 0.15735086798667908 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.09791181981563568 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.03467247635126114 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.11793988943099976 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.0600438192486763 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.028619658201932907 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.030015787109732628 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.057897888123989105 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.0738702267408371 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.04875720664858818 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.024392561987042427 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.03085465170443058 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.05044515058398247 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.029102379456162453 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.06290678679943085 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.1485225409269333 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.08931802213191986 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.046865396201610565 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.03757860139012337 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.037278078496456146 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.03275333344936371 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.11662371456623077 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.13080109655857086 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.04681439697742462 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.07702943682670593 \n",
      "Epoch: 81  Train Loss: 0.013513587415218353 - Test Loss 0.05273910239338875 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.14669661223888397 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.09155583381652832 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.17523404955863953 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.012956073507666588 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.04245346784591675 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.02226218208670616 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.035382144153118134 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.012005998753011227 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.07356774806976318 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.09779391437768936 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.03273823857307434 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.014842343516647816 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.06150268763303757 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.017956804484128952 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.2202114760875702 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.04926977679133415 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.10413885116577148 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.01777293160557747 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.06428232043981552 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.12963804602622986 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.08025065809488297 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.023432087153196335 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.0269855298101902 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.039496276527643204 \n",
      "Epoch: 82  Train Loss: 0.024188613519072533 - Test Loss 0.07335763424634933 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.02013501152396202 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.029910584911704063 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.03020528517663479 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.10060031712055206 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.021075360476970673 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.06603120267391205 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.01292699296027422 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.12389795482158661 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.010406794026494026 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.057863712310791016 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.060139693319797516 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.04658418148756027 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.03592044860124588 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.05983489751815796 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.038193993270397186 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.03160068020224571 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.08134336769580841 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.27284783124923706 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.03152232989668846 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.023875635117292404 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.029899489134550095 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.06417706608772278 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.024657603353261948 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.018556004390120506 \n",
      "Epoch: 83  Train Loss: 0.016865679994225502 - Test Loss 0.0588931068778038 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.03968598693609238 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.100483737885952 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.04972904920578003 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.029276331886649132 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.07013902813196182 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.09898228943347931 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.020534954965114594 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.06816434860229492 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.06082599610090256 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.03963490203022957 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.0475187785923481 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.054808955639600754 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.07915236055850983 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.029109830036759377 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.1015578880906105 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.19439657032489777 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.019715849310159683 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.024783074855804443 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.11932357400655746 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.024424437433481216 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.09395575523376465 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.049968134611845016 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.048296257853507996 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.02805395983159542 \n",
      "Epoch: 84  Train Loss: 0.012142248451709747 - Test Loss 0.12920337915420532 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.020096449181437492 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.028136366978287697 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.06359697878360748 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.030863502994179726 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.038182660937309265 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.05128685384988785 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.1753261536359787 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.02683129534125328 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.07152613252401352 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.10411349684000015 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.09133455157279968 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.1312803328037262 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.03681051731109619 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.039752937853336334 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.04645557329058647 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.03973258659243584 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.010794511064887047 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.0445726104080677 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.043220777064561844 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.08644711226224899 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.0485856719315052 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.0243991632014513 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.030772292986512184 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.04181702062487602 \n",
      "Epoch: 85  Train Loss: 0.019054079428315163 - Test Loss 0.09314616024494171 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.11968457698822021 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.01976439543068409 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.045865654945373535 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.03981049731373787 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.11457784473896027 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.03910939395427704 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.03688325732946396 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.007294066250324249 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.017318498343229294 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.09124699234962463 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.13788998126983643 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.021279124543070793 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.04174654558300972 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.018184492364525795 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.07767771929502487 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.13505390286445618 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.039359427988529205 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.010314257815480232 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.02266731485724449 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.02997767925262451 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.03316028416156769 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.02510456182062626 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.07787488400936127 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.01537355501204729 \n",
      "Epoch: 86  Train Loss: 0.018636953085660934 - Test Loss 0.07439775764942169 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.03803648799657822 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.024636026471853256 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.021175958216190338 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.02904900535941124 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.2201821357011795 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.02736082300543785 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.07084907591342926 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.08178355544805527 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.04631946608424187 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.04674253240227699 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.15171769261360168 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.046270616352558136 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.058394432067871094 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.030156409367918968 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.15741299092769623 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.07617200911045074 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.06615941971540451 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.07177004218101501 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.03639727085828781 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.19361530244350433 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.03133683651685715 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.02178623154759407 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.030665308237075806 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.024631138890981674 \n",
      "Epoch: 87  Train Loss: 0.03722783923149109 - Test Loss 0.020236503332853317 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.15191318094730377 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.09979262948036194 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.10186465084552765 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.0681263729929924 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.14291058480739594 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.171264186501503 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.12492628395557404 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.11521565914154053 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.03549204394221306 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.09740033000707626 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.12714362144470215 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.046180304139852524 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.11608313024044037 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.11632657051086426 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.04708317667245865 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.044539231806993484 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.04194498062133789 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.07156364619731903 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.0728047639131546 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.08594570308923721 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.14134415984153748 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.031575530767440796 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.16913919150829315 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.05475722625851631 \n",
      "Epoch: 88  Train Loss: 0.07096575200557709 - Test Loss 0.08343161642551422 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.01066572591662407 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.11219747364521027 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.029664626345038414 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.043796561658382416 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.026715105399489403 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.028925735503435135 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.06643835455179214 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.060103047639131546 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.031673312187194824 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.01584647223353386 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.043477270752191544 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.0148786511272192 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.07610659301280975 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.01682695746421814 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.016050735488533974 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.15842214226722717 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.03932448476552963 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.10756514221429825 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.044500142335891724 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.05829935148358345 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.0915631353855133 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.02631283923983574 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.01595703884959221 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.170857235789299 \n",
      "Epoch: 89  Train Loss: 0.021345168352127075 - Test Loss 0.025263627991080284 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.08789094537496567 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.06576134264469147 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.10816310346126556 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.12174934148788452 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.04729878902435303 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.026483815163373947 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.11741594225168228 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.03284158930182457 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.10517917573451996 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.02434505894780159 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.1106099933385849 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.03527327626943588 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.04901323467493057 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.09579136222600937 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.06332316994667053 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.009682358242571354 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.027974596247076988 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.028086503967642784 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.06731437891721725 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.022987429052591324 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.0551694855093956 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.07533545047044754 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.005663751158863306 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.0956067144870758 \n",
      "Epoch: 90  Train Loss: 0.02745906077325344 - Test Loss 0.09500714391469955 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.09537424147129059 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.17151950299739838 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.21760371327400208 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.04149644821882248 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.06310103088617325 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.11584440618753433 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.10085573047399521 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.08804978430271149 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.0537453293800354 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.1465190351009369 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.19682452082633972 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.20193204283714294 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.08009366691112518 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.09522704035043716 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.05289364606142044 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.09996642917394638 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.05697835609316826 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.08927258104085922 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.037644464522600174 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.014582274481654167 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.10198287665843964 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.047288332134485245 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.12962788343429565 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.038630589842796326 \n",
      "Epoch: 91  Train Loss: 0.07307429611682892 - Test Loss 0.128617063164711 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.04155384376645088 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.07954582571983337 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.1534971296787262 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.00918915867805481 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.03260521590709686 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.06235568970441818 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.03565669059753418 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.015297263860702515 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.14397184550762177 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.01406621653586626 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.023153971880674362 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.022549180313944817 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.16121326386928558 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.06144145131111145 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.019478974863886833 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.051959045231342316 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.032547540962696075 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.04113614186644554 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.03956996649503708 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.02773636020720005 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.024248573929071426 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.0607810840010643 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.05267505720257759 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.06386175006628036 \n",
      "Epoch: 92  Train Loss: 0.007762514986097813 - Test Loss 0.04305066913366318 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.0459071546792984 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.05362588167190552 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.07938794046640396 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.0446668341755867 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.02885347604751587 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.013560843653976917 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.034815896302461624 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.018536102026700974 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.16191980242729187 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.1414879560470581 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.11538191139698029 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.1394689381122589 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.01783641055226326 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.01323616225272417 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.05942734330892563 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.02121054008603096 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.015180498361587524 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.010849066078662872 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.07287672162055969 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.011801168322563171 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.016111131757497787 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.015283403918147087 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.018765544518828392 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.07945619523525238 \n",
      "Epoch: 93  Train Loss: 0.010171045549213886 - Test Loss 0.06388934701681137 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.0743451789021492 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.08150898665189743 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.21447107195854187 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.027016524225473404 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.03662890940904617 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.04976000636816025 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.013070380315184593 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.05471576377749443 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.04124037176370621 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.18660977482795715 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.027633031830191612 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.032278500497341156 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.03891759365797043 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.015813438221812248 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.028024237602949142 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.03809880465269089 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.008121912367641926 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.055189359933137894 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.014848952181637287 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.035291459411382675 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.11292318999767303 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.03890687972307205 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.024881504476070404 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.01904383674263954 \n",
      "Epoch: 94  Train Loss: 0.006562655325978994 - Test Loss 0.03912509232759476 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.10050711780786514 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.014882956631481647 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.03065074421465397 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.0476391538977623 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.02784932218492031 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.015455749817192554 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.009347353130578995 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.012537522241473198 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.011200089938938618 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.14553196728229523 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.03994671255350113 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.011523130349814892 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.03223039582371712 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.09162361919879913 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.032064180821180344 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.02139989100396633 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.059160053730010986 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.06345309317111969 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.027532514184713364 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.052191637456417084 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.020639454945921898 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.05878933519124985 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.022163400426506996 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.314423143863678 \n",
      "Epoch: 95  Train Loss: 0.015137570910155773 - Test Loss 0.097688227891922 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.01177419163286686 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.10878671705722809 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.04103974997997284 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.018579792231321335 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.20472565293312073 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.041127368807792664 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.045160360634326935 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.041200168430805206 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.06606368720531464 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.012169408611953259 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.033023130148649216 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.011412288062274456 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.1940770447254181 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.006332823541015387 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.1086813434958458 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.1672452837228775 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.034250035881996155 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.027526726946234703 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.011679394170641899 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.023298142477869987 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.04978155344724655 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.019650261849164963 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.037561848759651184 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.013711206614971161 \n",
      "Epoch: 96  Train Loss: 0.040153853595256805 - Test Loss 0.06347454339265823 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.08423827588558197 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.09635908156633377 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.026155564934015274 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.023974357172846794 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.17115293443202972 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.015210635960102081 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.038856249302625656 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.07170514762401581 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.11684610694646835 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.06934807449579239 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.041058339178562164 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.12703731656074524 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.09980341792106628 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.08507854491472244 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.04648308828473091 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.0662466436624527 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.04047275707125664 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.015701696276664734 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.029660943895578384 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.04501308500766754 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.07045947760343552 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.03046335279941559 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.06446930021047592 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.04788481816649437 \n",
      "Epoch: 97  Train Loss: 0.04375644400715828 - Test Loss 0.08008459955453873 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.007539086043834686 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.009660834446549416 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.03399861976504326 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.00832381658256054 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.021877411752939224 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.0372559130191803 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.05728013440966606 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.028645236045122147 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.15115578472614288 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.15231284499168396 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.014941017143428326 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.016674891114234924 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.011423919349908829 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.013400117866694927 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.2086152583360672 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.06348066031932831 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.09739839285612106 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.01450730673968792 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.026978367939591408 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.038610707968473434 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.029527977108955383 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.010589920915663242 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.18219417333602905 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.04619792848825455 \n",
      "Epoch: 98  Train Loss: 0.0039171455428004265 - Test Loss 0.024197157472372055 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.10716976225376129 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.0272259172052145 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.006240092217922211 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.1347229778766632 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.05576983094215393 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.18207836151123047 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.045214828103780746 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.049884527921676636 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.04013144597411156 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.06807830929756165 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.014480473473668098 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.00787784717977047 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.018692204728722572 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.04566044732928276 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.04680977389216423 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.02593819797039032 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.022257620468735695 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.043689802289009094 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.03724532946944237 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.08041074126958847 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.030517837032675743 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.06843478232622147 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.04922989010810852 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.10264476388692856 \n",
      "Epoch: 99  Train Loss: 0.007436873856931925 - Test Loss 0.04449242725968361 \n",
      "Computation completed! \n",
      "---\n",
      "Training complete in 3m 27s\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Train Model\n",
    "start = time.time()\n",
    "\n",
    "# training setup \n",
    "num_epochs = 100  # na začátku dej 1 - abychom otestovali, jestli loop funguje\n",
    "\n",
    "# log loss history - uložíme to do slovníků\n",
    "train_loss, test_loss = [], []\n",
    "\n",
    "# loop over the epoches \n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for phase in ['train', 'test']: # poběží tu dva procesy, které se prostřídají\n",
    "        if phase == 'train':\n",
    "            model.train(True)  # Set training mode = true\n",
    "            dataloader = train_dataloader\n",
    "        else:\n",
    "            model.train(False)  # Set model to evaluate mode\n",
    "            dataloader = test_dataloader\n",
    "\n",
    "        step = 0\n",
    "\n",
    "        # iterate over batches of data\n",
    "        for X, Y, y_label in dataloader:    # dataloader vrací: image, mask and labels for the image\n",
    "            step += 1\n",
    "\n",
    "            # make the input X and y Pytorch Variable() (with gradient)\n",
    "            x = Variable(X)\n",
    "            y_l = Variable(y_label)\n",
    "         \n",
    "            # TRAINING PHASE\n",
    "            # run forward pass\n",
    "            if phase == 'train':\n",
    "                # zero the gradients\n",
    "                omptimizer.zero_grad()\n",
    "\n",
    "                # calcualte model outputs based on input X \n",
    "                outputs = model(x)\n",
    "\n",
    "                # calcualte loss based on your criterion \n",
    "                loss = criteria(outputs, torch.tensor(y_l, dtype = torch.long))\n",
    "\n",
    "                # the backward pass frees the graph memory, so there is no need for torch.no_grad in this training pass back propagation \n",
    "                loss.backward()\n",
    "\n",
    "                # optimizer step \n",
    "                omptimizer.step()\n",
    "            \n",
    "\n",
    "            # TESTING PHASE\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    # calculate model outputs based on input X \n",
    "                    output = model(x)\n",
    "\n",
    "                    # calculate loss (beavaere it takes Long (integer) for cathegorical values)\n",
    "                    loss = criteria(output, torch.tensor(y_l, dtype = torch.long)) \n",
    "            \n",
    "            # save losses and print them \n",
    "            if phase=='train': \n",
    "                train_loss.append(loss)\n",
    "                #print('Epoch: {}  Train Loss: {} '.format(epoch, loss)) \n",
    "            else: \n",
    "                # append test loss\n",
    "                test_loss.append(loss)\n",
    "                #print('Epoch: {}  Test Loss: {} '.format(epoch, loss)) \n",
    "\n",
    "                # report epoch\n",
    "                print('Epoch: {}  Train Loss: {} - Test Loss {} '.format(epoch, train_loss[-1], test_loss[-1]))\n",
    "                                        \n",
    "\n",
    "print('Computation completed! ')\n",
    "print('---')\n",
    "time_elapsed = time.time() - start\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss i test_loss je tenzor, takže to musíme detachnout, aby to šlo vyplotovat\n",
    "train_loss_d = [d.detach() for d in train_loss]\n",
    "test_loss_d = [d.detach() for d in test_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_d, label = \"Train loss\")\n",
    "plt.plot(test_loss_d, label = \"Test loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"number of epochs * batches\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpretace grafíku?\n",
    "- **peaks** = vzorek mám rozdělený do batches a občas to rozdělení není úplně ideální a to způsobuje ty peaks, protože model ty data ještě neviděl, tak šmudla panikaří\n",
    "- **výsledná loss** je v poslední epoše"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
